{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12afe148",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a347ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "#from sklearn import linear_model\n",
    "import matplotlib.pyplot as pyplot\n",
    "import pickle\n",
    "from matplotlib import style\n",
    "\n",
    "data = pd.read_csv(\"student-mat.csv\", sep=\";\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"G1\", \"G2\", \"G3\", \"studytime\", \"failures\", \"absences\"]]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64f595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = \"G3\"\n",
    "\n",
    "X = np.array(data.drop([predict], axis=1))\n",
    "y = np.array(data[predict])\n",
    "\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "\n",
    "\"\"\"best = 0\n",
    "for _ in range(30):\n",
    "\n",
    "    x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "    linear = linear_model.LinearRegression()\n",
    "\n",
    "    linear.fit(x_train, y_train)\n",
    "\n",
    "    acc = linear.score(x_test, y_test)\n",
    "    print(acc)\n",
    "\n",
    "    if acc > best:\n",
    "        best = acc\n",
    "        # saves model\n",
    "        with open(\"studentmodel.pickle\", \"wb\") as f:\n",
    "            pickle.dump(linear, f)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93305a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"studentmodel.pickle\", \"rb\")\n",
    "linear = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53528b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coefficient:\", linear.coef_)\n",
    "print(\"Intercept:\", linear.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf80fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = linear.predict(x_test)\n",
    "\n",
    "for x in range(len(predictions)):\n",
    "    print(predictions[x], x_test[x], y_test[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48526e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"absences\"\n",
    "style.use(\"ggplot\")\n",
    "pyplot.scatter(data[p], data[\"G3\"])\n",
    "pyplot.xlabel(p)\n",
    "pyplot.ylabel(\"Final Grade\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b862c3",
   "metadata": {},
   "source": [
    "# Classification - K Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f01baf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model, preprocessing\n",
    "\n",
    "data = pd.read_csv(\"car.data\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523643c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "buying = le.fit_transform(list(data[\"buying\"]))\n",
    "maint = le.fit_transform(list(data[\"maint\"]))\n",
    "door = le.fit_transform(list(data[\"door\"]))\n",
    "persons = le.fit_transform(list(data[\"persons\"]))\n",
    "lug_boot = le.fit_transform(list(data[\"lug_boot\"]))\n",
    "safety = le.fit_transform(list(data[\"safety\"]))\n",
    "clss = le.fit_transform(list(data[\"class\"]))\n",
    "print(buying)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c29fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = \"class\"\n",
    "\n",
    "X = list(zip(buying, maint, door, persons, lug_boot, safety))\n",
    "y = list(clss)\n",
    "\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9d6667",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=9)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "acc = model.score(x_test, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(x_test)\n",
    "names = [\"unacc\", \"acc\", \"good\", \"vgood\"]\n",
    "\n",
    "for x in range(len(predicted)):\n",
    "    print(\"Predicted: \", names[predicted[x]], \"Data: \", tuple(int(val) for val in x_test[x]), \"Actual: \", names[y_test[x]])\n",
    "    n = model.kneighbors([x_test[x]], 9, True)\n",
    "    print(\"N: \", n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c75c3d",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81804358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "print(cancer.feature_names)\n",
    "print(cancer.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0353601",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "print(x_train, y_train)\n",
    "classes = [\"malignant\", \"benign\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d537c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel=\"linear\", C=2)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "clf2 = KNeighborsClassifier(n_neighbors=9)\n",
    "clf2.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "y_pred_2 = clf2.predict(x_test)\n",
    "\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "acc2 = metrics.accuracy_score(y_test, y_pred_2)\n",
    "\n",
    "print(\"SVM: \", acc)\n",
    "print(\"KNN: \", acc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b722741",
   "metadata": {},
   "source": [
    "# K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fac739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "digits = load_digits()\n",
    "data = scale(digits.data)\n",
    "\n",
    "y = digits.target\n",
    "\n",
    "# k = len(np.unique(y))\n",
    "k = 10\n",
    "\n",
    "samples, features = data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dceb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bench_k_means(estimator, name, data):\n",
    "    estimator.fit(data)\n",
    "    print('%-9s\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f'\n",
    "          % (name, estimator.inertia_,\n",
    "             metrics.homogeneity_score(y, estimator.labels_),\n",
    "             metrics.completeness_score(y, estimator.labels_),\n",
    "             metrics.v_measure_score(y, estimator.labels_),\n",
    "             metrics.adjusted_rand_score(y, estimator.labels_),\n",
    "             metrics.adjusted_mutual_info_score(y,  estimator.labels_),\n",
    "             metrics.silhouette_score(data, estimator.labels_,\n",
    "                                      metric='euclidean')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f359909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KMeans(n_clusters=k, init=\"random\", n_init=10)\n",
    "bench_k_means(clf, \"1\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbf5c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "digits = load_digits()\n",
    "data = scale(digits.data)\n",
    "\n",
    "n_samples, n_features = data.shape\n",
    "n_digits = len(np.unique(digits.target))\n",
    "labels = digits.target\n",
    "\n",
    "sample_size = 300\n",
    "\n",
    "print(\"n_digits: %d, \\t n_samples %d, \\t n_features %d\"\n",
    "      % (n_digits, n_samples, n_features))\n",
    "\n",
    "\n",
    "print(82 * '_')\n",
    "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
    "\n",
    "\n",
    "def bench_k_means(estimator, name, data):\n",
    "    t0 = time()\n",
    "    estimator.fit(data)\n",
    "    print('%-9s\\t%.2fs\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f'\n",
    "          % (name, (time() - t0), estimator.inertia_,\n",
    "             metrics.homogeneity_score(labels, estimator.labels_),\n",
    "             metrics.completeness_score(labels, estimator.labels_),\n",
    "             metrics.v_measure_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_rand_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\n",
    "             metrics.silhouette_score(data, estimator.labels_,\n",
    "                                      metric='euclidean',\n",
    "                                      sample_size=sample_size)))\n",
    "\n",
    "bench_k_means(KMeans(init='k-means++', n_clusters=n_digits, n_init=10),\n",
    "              name=\"k-means++\", data=data)\n",
    "\n",
    "bench_k_means(KMeans(init='random', n_clusters=n_digits, n_init=10),\n",
    "              name=\"random\", data=data)\n",
    "\n",
    "\n",
    "print(82 * '_')\n",
    "\n",
    "# #############################################################################\n",
    "# Visualize the results on PCA-reduced data\n",
    "\n",
    "reduced_data = PCA(n_components=2).fit_transform(data)\n",
    "kmeans = KMeans(init='k-means++', n_clusters=n_digits, n_init=10)\n",
    "kmeans.fit(reduced_data)\n",
    "\n",
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.imshow(Z, interpolation='nearest',\n",
    "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "           cmap=plt.cm.Paired,\n",
    "           aspect='auto', origin='lower')\n",
    "\n",
    "plt.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=2)\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "            marker='x', s=169, linewidths=3,\n",
    "            color='w', zorder=10)\n",
    "plt.title('K-means clustering on the digits dataset (PCA-reduced data)\\n'\n",
    "          'Centroids are marked with white cross')\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-ml-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
